{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lGAr2ra7MILH"
      },
      "outputs": [],
      "source": [
        "!unzip -q data.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtEE3hbuPnhf",
        "outputId": "17143a2c-0a42-42b4-c527-2e2c0412c251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           HTML_Text         Target\n",
            "0  2018 2017 ASSETS Non-Current Assets Property P...  Balance Sheet\n",
            "1  1 Standalone Consolidated | As at Mar As at Ma...  Balance Sheet\n",
            "2  Standalone Consolidated Particulars Year Ended...  Balance Sheet\n",
            "3  As at 31st March, As at 31st March, Statement ...  Balance Sheet\n",
            "4  March 31,2018 March 31,2017 ASSETS Non-current...  Balance Sheet\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def read_html_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return file.read()\n",
        "\n",
        "def extract_text_from_html(html_content):\n",
        "    # Parse HTML content\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Extract text from the parsed HTML\n",
        "    text = soup.get_text(separator=' ')\n",
        "\n",
        "    # Remove extra spaces, newlines, and tabs\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "def process_directory(directory, label):\n",
        "    data = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith('.html'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                html_content = read_html_file(file_path)\n",
        "                clean_text = extract_text_from_html(html_content)\n",
        "                data.append((clean_text, label))\n",
        "    return data\n",
        "\n",
        "# Paths to the directories with HTML files and their corresponding labels\n",
        "directories = {\n",
        "    '/content/data/data/Balance Sheets': 'Balance Sheet',\n",
        "    '/content/data/data/Cash Flow': 'Cash Flow',\n",
        "    '/content/data/data/Income Statement': 'Income Statement',\n",
        "    '/content/data/data/Notes': 'Notes',\n",
        "    '/content/data/data/Others': 'Others'\n",
        "}\n",
        "\n",
        "# Collect data from all directories\n",
        "all_data = []\n",
        "for directory, label in directories.items():\n",
        "    all_data.extend(process_directory(directory, label))\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame(all_data, columns=['HTML_Text', 'Target'])\n",
        "\n",
        "# Saved DataFrame to a CSV file (optional)\n",
        "df.to_csv('financial_statements.csv', index=False)\n",
        "\n",
        "# Displaying the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP4TSG4ec3WL",
        "outputId": "422da02b-6042-4898-b5c4-1845851de77c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           HTML_Text         Target\n",
            "0  2018 2017 assets non current assets property p...  Balance Sheet\n",
            "1  1 standalone consolidated as at mar as at mar ...  Balance Sheet\n",
            "2  standalone consolidated particulars year ended...  Balance Sheet\n",
            "3  as at 31st march as at 31st march statement of...  Balance Sheet\n",
            "4  march 31 2018 march 31 2017 assets non current...  Balance Sheet\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/financial_statements.csv')\n",
        "\n",
        "# Function to clean the text\n",
        "def clean_text(text):\n",
        "    # Remove non-alphanumeric characters\n",
        "    text = re.sub(r'\\W+', ' ', text)\n",
        "    # Convert to lower case\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Apply the clean_text function to the HTML_Text column\n",
        "df['HTML_Text'] = df['HTML_Text'].apply(clean_text)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQuawVR3dqlF",
        "outputId": "861fcc47-920c-43ae-b94b-a54f7ac21af6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8574257425742574\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Balance Sheet       1.00      0.94      0.97        51\n",
            "       Cash Flow       0.00      0.00      0.00         6\n",
            "Income Statement       1.00      0.65      0.79        66\n",
            "           Notes       0.88      0.74      0.81       123\n",
            "          Others       0.81      0.97      0.88       259\n",
            "\n",
            "        accuracy                           0.86       505\n",
            "       macro avg       0.74      0.66      0.69       505\n",
            "    weighted avg       0.86      0.86      0.85       505\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['HTML_Text'], df['Target'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating a pipeline that combines the TF-IDF vectorizer and a Naive Bayes classifier\n",
        "pipeline = make_pipeline(TfidfVectorizer(max_features=10000), MultinomialNB())\n",
        "\n",
        "# Training the model on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the labels for the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluating the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YweM8tXgilfx"
      },
      "source": [
        "**Using MNB Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWzA6dD-ejvB",
        "outputId": "08675737-9f0a-4e70-f4a5-afd4f5b7dce2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['text_classification_model.pkl']"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Saving the trained model to a file\n",
        "joblib.dump(pipeline, 'text_classification_model.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISsTVZf9ixgO"
      },
      "source": [
        "**Testing the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpP0EIKIeg39",
        "outputId": "8c4a195c-286b-454d-88b6-3bbef97a1170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Balance Sheet']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Loading the saved model from the file (for later use)\n",
        "loaded_model = joblib.load('text_classification_model.pkl')\n",
        "\n",
        "# Function to extract text from HTML file\n",
        "def extract_text_from_html(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    text = soup.get_text(separator=' ')\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Function to predict the category of HTML files\n",
        "def predict_category_from_html(file_paths):\n",
        "    texts = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        html_content = file.read()\n",
        "        text = extract_text_from_html(html_content)\n",
        "        cleaned_text = clean_text(text)\n",
        "        texts.append(cleaned_text)\n",
        "    predictions = loaded_model.predict(texts)\n",
        "    return predictions\n",
        "\n",
        "# Example usage\n",
        "html_file_paths = [\n",
        "    \"/content/data/data/Balance Sheets/18445487_2.html\"]\n",
        "predicted_categories = predict_category_from_html(html_file_paths)\n",
        "print(predicted_categories)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXVJPnZni4-D"
      },
      "source": [
        "**Using LogisticRegression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSuyK1_lgN7z",
        "outputId": "41a9fa92-1a27-4bcf-ff44-b74af048c242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.9485148514851485\n",
            "Logistic Regression Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Balance Sheet       0.98      1.00      0.99        51\n",
            "       Cash Flow       1.00      0.83      0.91         6\n",
            "Income Statement       0.97      0.94      0.95        66\n",
            "           Notes       0.98      0.86      0.92       123\n",
            "          Others       0.92      0.98      0.95       259\n",
            "\n",
            "        accuracy                           0.95       505\n",
            "       macro avg       0.97      0.92      0.94       505\n",
            "    weighted avg       0.95      0.95      0.95       505\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Creating a pipeline that combines the TF-IDF vectorizer and a Logistic Regression classifier\n",
        "pipeline_lr = make_pipeline(TfidfVectorizer(max_features=10000), LogisticRegression())\n",
        "\n",
        "# Training the model on the training data\n",
        "pipeline_lr.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the labels for the test set\n",
        "y_pred_lr = pipeline_lr.predict(X_test)\n",
        "\n",
        "# Evaluating the model's performance\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "report_lr = classification_report(y_test, y_pred_lr)\n",
        "\n",
        "print(f'Logistic Regression Accuracy: {accuracy_lr}')\n",
        "print('Logistic Regression Classification Report:')\n",
        "print(report_lr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kDR9fLijNQO"
      },
      "source": [
        "**Testing the LR model predictions on a sample**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ6DvdkHg-Cu",
        "outputId": "0a8ee650-1bda-4c83-885a-a2e15fe2228b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Cash Flow']\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Saving the trained model to a file\n",
        "joblib.dump(pipeline, 'text_classification_model1.pkl')\n",
        "\n",
        "# Loaded the saved model from the file (for later use)\n",
        "loaded_model = joblib.load('text_classification_model1.pkl')\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\W+', ' ', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Function to extract text from HTML file\n",
        "def extract_text_from_html(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    text = soup.get_text(separator=' ')\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Function to predict the category of HTML files\n",
        "def predict_category_from_html(file_paths):\n",
        "    texts = []\n",
        "    for file_path in file_paths:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            html_content = file.read()\n",
        "            text = extract_text_from_html(html_content)\n",
        "            cleaned_text = clean_text(text)\n",
        "            texts.append(cleaned_text)\n",
        "    predictions = loaded_model.predict(texts)\n",
        "    return predictions\n",
        "\n",
        "# Example usage\n",
        "html_file_paths = [\n",
        "    \"/content/data/data/Cash Flow/18599651_table_100.html\"\n",
        "]\n",
        "predicted_categories = predict_category_from_html(html_file_paths)\n",
        "print(predicted_categories)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6sfORrRlsYg"
      },
      "source": [
        "**Best Selected Classification model from different models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aprALseehvQ5",
        "outputId": "5e0c44df-6e6b-4974-a09d-d60a2d633540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.9584158415841584\n",
            "SVM Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Balance Sheet       1.00      1.00      1.00        51\n",
            "       Cash Flow       1.00      0.83      0.91         6\n",
            "Income Statement       0.98      0.97      0.98        66\n",
            "           Notes       0.96      0.89      0.92       123\n",
            "          Others       0.94      0.98      0.96       259\n",
            "\n",
            "        accuracy                           0.96       505\n",
            "       macro avg       0.98      0.93      0.95       505\n",
            "    weighted avg       0.96      0.96      0.96       505\n",
            "\n",
            "Random Forest Accuracy: 0.9366336633663367\n",
            "Random Forest Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Balance Sheet       0.98      0.98      0.98        51\n",
            "       Cash Flow       1.00      0.67      0.80         6\n",
            "Income Statement       1.00      0.94      0.97        66\n",
            "           Notes       0.93      0.85      0.89       123\n",
            "          Others       0.92      0.97      0.94       259\n",
            "\n",
            "        accuracy                           0.94       505\n",
            "       macro avg       0.97      0.88      0.92       505\n",
            "    weighted avg       0.94      0.94      0.94       505\n",
            "\n",
            "Gradient Boosting Accuracy: 0.9405940594059405\n",
            "Gradient Boosting Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Balance Sheet       1.00      1.00      1.00        51\n",
            "       Cash Flow       1.00      0.67      0.80         6\n",
            "Income Statement       0.98      0.94      0.96        66\n",
            "           Notes       0.95      0.85      0.89       123\n",
            "          Others       0.92      0.98      0.95       259\n",
            "\n",
            "        accuracy                           0.94       505\n",
            "       macro avg       0.97      0.89      0.92       505\n",
            "    weighted avg       0.94      0.94      0.94       505\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Loading the CSV file into a DataFrame\n",
        "df = pd.read_csv('financial_statements.csv')\n",
        "\n",
        "# Function to clean the text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\W+', ' ', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Applying the clean_text function to the HTML_Text column\n",
        "df['HTML_Text'] = df['HTML_Text'].apply(clean_text)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['HTML_Text'], df['Target'], test_size=0.2, random_state=42)\n",
        "\n",
        "# List of different models to evaluate \n",
        "models = {\n",
        "    'SVM': SVC(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "\n",
        "# Evaluating each model\n",
        "for name, model in models.items():\n",
        "    pipeline = make_pipeline(TfidfVectorizer(max_features=10000), model)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    print(f'{name} Accuracy: {accuracy}')\n",
        "    print(f'{name} Classification Report:')\n",
        "    print(report)\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model = pipeline\n",
        "\n",
        "# Saving the best performing model\n",
        "if best_model is not None:\n",
        "    joblib.dump(best_model, 'best_model.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OGHUV8wlzIf"
      },
      "source": [
        "**Testing the best selected models prediction by giving 2 different html files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "QKVdHgepjmeL"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from bs4 import BeautifulSoup\n",
        "# Loading the saved model from the file (for later use)\n",
        "loaded_model = joblib.load('best_model.pkl')\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\W+', ' ', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Function to extract text from HTML file\n",
        "def extract_text_from_html(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    text = soup.get_text(separator=' ')\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Function to predict the category of HTML files\n",
        "def predict_category_from_html(file_paths):\n",
        "    texts = []\n",
        "    for file_path in file_paths:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            html_content = file.read()\n",
        "            text = extract_text_from_html(html_content)\n",
        "            cleaned_text = clean_text(text)\n",
        "            texts.append(cleaned_text)\n",
        "    predictions = loaded_model.predict(texts)\n",
        "    return predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OqcPYk7ljY9",
        "outputId": "ca9fd38d-543a-43e0-f673-bba1e7b0c628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Income Statement' 'Notes']\n"
          ]
        }
      ],
      "source": [
        "html_file_paths = [\n",
        "    \"/content/data/data/Income Statement/18448274_1.html\",\n",
        "    \"/content/data/data/Notes/18599651_table_109.html\"\n",
        "]\n",
        "predicted_categories = predict_category_from_html(html_file_paths)\n",
        "print(predicted_categories)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
